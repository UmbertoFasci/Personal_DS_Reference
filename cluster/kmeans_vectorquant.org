#+title: K-means clustering and Vector Quantization

* scipy.cluster.vq

Provides routines for k-means clustering, generating code books from k-means models and quantizing vectors by comparing them with centroids in a code book.

| whiten(obs[, check_finite                    | Normalize a group of observations on a per feature basis.                   |
| vq(obs, code_book[,check_finite])            | Assign codes from a code book to observations.                              |
| kmeans(obs, k_or_guess[, iter, thresh, ...]) | Performs k-means on a set of observation vectors forming k clusters.        |
| kmeans2(data, k[, iter, thresh, minit, ...]) | Classify a set of observations into k clusters using the k-means algorithm. |

** Background information

The k-means algorithm takes as input the number of clusters to generate, k, and a set of observation vectors to cluster. It returns a set of centroids, one for each of the k clusters. An observation vector is classified with the cluster number or centroid index of the centroid closest to it.

A vector ~v~ belongs to cluster ~i~ if it is closer to centroid ~i~ than any other centroid. If ~v~ belongs to ~i~, we say centroid ~i~ is the dominating centroid of ~v~. The k-means algorithm tries to minimize distortion, which is defined as the sum of the squared distances between each observation vector and its dominating centroid. The minimization is achieved by iteratively reclassifying the observations into clusters and recalculating the centroids until a configuration is reached in which the centroids are stable. One can also define a maximum number of iterations.

Since vector quantization is a natural application for k-means, information theory terminology is often used. The centroid index or cluster index is also referred to as a “code” and the table mapping codes to centroids and, vice versa, is often referred to as a “code book”. The result of k-means, a set of centroids, can be used to quantize vectors. Quantization aims to find an encoding of vectors that reduces the expected distortion.

All routines expect obs to be an M by N array, where the rows are the observation vectors. The codebook is a k by N array, where the ith row is the centroid of code word ~i~. The observation vectors and centroids have the same feature dimension.

As an example, suppose we wish to compress a 24-bit color image (each pixel is represented by one byte for red, one for blue, and one for green) before sending it over the web. By using a smaller 8-bit encoding, we can reduce the amount of data by two thirds. Ideally, the colors for each of the 256 possible 8-bit encoding values should be chosen to minimize distortion of the color. Running k-means with k=256 generates a code book of 256 codes, which fills up all possible 8-bit sequences. Instead of sending a 3-byte value for each pixel, the 8-bit centroid index (or code word) of the dominating centroid is transmitted. The code book is also sent over the wire so each 8-bit code can be translated back to a 24-bit pixel value representation. If the image of interest was of an ocean, we would expect many 24-bit blues to be represented by 8-bit codes. If it was an image of a human face, more flesh-tone colors would be represented in the code book.


** scipy.cluster.vq.whiten

Normalize a group of observations on a per feature basis. Before running k-means, it is beneficial to rescale each feature dimension of the observation set by its standard deviation. Each feature is divided by its standard deviation across all observations to give it unit variance.

#+begin_src jupyter-python
import numpy as np
from scipy.cluster.vq import whiten
features = np.array([[1.9, 2.3, 1.7],
                     [1.5, 2.5, 2.2],
                     [0.8, 0.6, 1.7]])

whiten(features)
#+end_src

#+RESULTS:
: array([[4.17944278, 2.69811351, 7.21248917],
:        [3.29956009, 2.93273208, 9.33380951],
:        [1.75976538, 0.7038557 , 7.21248917]])


** scipy.cluster.vq.vq

Assign codes from a code book to observations.

#+begin_src jupyter-python
import numpy as np
from scipy.cluster.vq import vq

code_book = np.array([[1., 1., 1.],
                      [2., 2., 2.]])

features = np.array([[1.9,2.3,1.7],
                     [1.5,2.5,2.2],
                     [0.8,0.6,1.7]])

vq(features, code_book)
#+end_src

#+RESULTS:
| array | ((1 1 0) dtype=int32) | array | ((0.43588989 0.73484692 0.83066239)) |


to continue...
